{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get webpage\n",
    "def simple_get(url):\n",
    "    \n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_resp(resp):\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "            \n",
    "    except RequestException as e:\n",
    "        log_error(f'Error during requsts to {url}: {str(e)}')\n",
    "        return None\n",
    "    \n",
    "def is_good_resp(resp):\n",
    "    \n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200\n",
    "            and content_type is not None\n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "def log_error(e):\n",
    "    \n",
    "    print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30899"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search parameters Data Scientist jobs in Greater Los Angeles\n",
    "raw_html = simple_get('https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=data%20scientist&location=Long%20Beach%2C%20California%2C%20United%20States&trk=homepage-jobseeker_jobs-search-bar_search-submit&redirect=false&position=1&pageNum=0&start=75')\n",
    "len(raw_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse and filter using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parse raw html\n",
    "html1 = BeautifulSoup(raw_html, 'html.parser')\n",
    "#print(html.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function to gather data for each job\n",
    "def get_urls(num_of_jobs):\n",
    "    list_no = 0\n",
    "    \n",
    "    while list_no < num_of_jobs:\n",
    "        url = f'https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=data%20scientist&location=Long%20Beach%2C%20California%2C%20United%20States&trk=homepage-jobseeker_jobs-search-bar_search-submit&redirect=false&position=1&pageNum=0&start={list_no}'\n",
    "        print(url)\n",
    "        list_no += 25\n",
    "        \n",
    "#get_urls(100)\n",
    "\n",
    "def sieve_page(html):\n",
    "    \n",
    "    # find all job listing titles\n",
    "    job_list = html.find_all(class_='result-card job-result-card result-card--with-hover-state')\n",
    "    #print(job_list)\n",
    "\n",
    "    page_list = []\n",
    "    \n",
    "    if len(job_list) > 0:\n",
    "        for job in job_list:\n",
    "            title = job.find('h3').text\n",
    "            company = job.find('h4').text\n",
    "            location = job.find(class_='job-result-card__location').text\n",
    "            description = job.find('p').text\n",
    "            link = job.find('a').get('href')\n",
    "\n",
    "            sieved_job = [title, company, location, description, link]\n",
    "            page_list.append(sieved_job)\n",
    "\n",
    "        print(len(page_list))\n",
    "           \n",
    "        return page_list\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#sieve_page(html1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape desired number of jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "17\n",
      "25\n",
      "14\n",
      "25\n",
      "17\n",
      "25\n",
      "22\n",
      "25\n",
      "24\n",
      "25\n",
      "21\n",
      "25\n",
      "16\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# let's combine the functions to do all processes in one fell swoop\n",
    "# takes the total number of jobs to scrape as the argument\n",
    "def sieve_all_pages(desired_num_of_jobs):\n",
    "    list_pos = 0\n",
    "    sieved_list = []\n",
    "    \n",
    "    while list_pos < desired_num_of_jobs:\n",
    "        \n",
    "        # while the position is less than number of jobs I want to scrape go to next page\n",
    "        url = f'https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=data%20scientist&location=Long%20Beach%2C%20California%2C%20United%20States&trk=homepage-jobseeker_jobs-search-bar_search-submit&redirect=false&position=1&pageNum=0&start={list_pos}'\n",
    "        \n",
    "        # get page\n",
    "        raw_html = simple_get(url)\n",
    "        \n",
    "        # parse using BeautifulSoup\n",
    "        html = BeautifulSoup(raw_html, 'html.parser')\n",
    "        \n",
    "        # use sieve_page function to gather relevant data and add to main list\n",
    "        new_list = sieve_page(html)\n",
    "        \n",
    "        if len(new_list) > 0:\n",
    "            sieved_list += new_list\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        # change to new position\n",
    "        list_pos += 25\n",
    "\n",
    "    return sieved_list\n",
    "\n",
    "my_jobs = sieve_all_pages(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Los Angeles, CA, US</td>\n",
       "      <td>What You Will Be Doing. What we are really loo...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Jobot</td>\n",
       "      <td>Irvine, CA, US</td>\n",
       "      <td>What can we do for you? We are looking for…. T...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist, Analytics</td>\n",
       "      <td>NEXT Trucking</td>\n",
       "      <td>Los Angeles, CA, US</td>\n",
       "      <td>Armed with experienced professionals from Amaz...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>The CSI Companies</td>\n",
       "      <td>Costa Mesa, California</td>\n",
       "      <td>Our comprehensive and employee centric trainin...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-data-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR. Data Scientist</td>\n",
       "      <td>DISYS</td>\n",
       "      <td>Santa Monica, California</td>\n",
       "      <td>The ideal candidate is adept at using large da...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-data-sci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title             company                  location  \\\n",
       "0      Senior Data Scientist  Jobspring Partners       Los Angeles, CA, US   \n",
       "1             Data Scientist               Jobot            Irvine, CA, US   \n",
       "2  Data Scientist, Analytics       NEXT Trucking       Los Angeles, CA, US   \n",
       "3        Lead Data Scientist   The CSI Companies    Costa Mesa, California   \n",
       "4         SR. Data Scientist               DISYS  Santa Monica, California   \n",
       "\n",
       "                                         description  \\\n",
       "0  What You Will Be Doing. What we are really loo...   \n",
       "1  What can we do for you? We are looking for…. T...   \n",
       "2  Armed with experienced professionals from Amaz...   \n",
       "3  Our comprehensive and employee centric trainin...   \n",
       "4  The ideal candidate is adept at using large da...   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.linkedin.com/jobs/view/senior-data...  \n",
       "1  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "2  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "3  https://www.linkedin.com/jobs/view/lead-data-s...  \n",
       "4  https://www.linkedin.com/jobs/view/sr-data-sci...  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(my_jobs, columns=['title', 'company', 'location', 'description', 'link'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 5)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
